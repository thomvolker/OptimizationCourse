[
  {
    "objectID": "chapter6.html",
    "href": "chapter6.html",
    "title": "6  Iteration-based Function Optimization",
    "section": "",
    "text": "Chapter 2 on motivating problems is the first chapter that actually entails exercises."
  },
  {
    "objectID": "chapter6.html#exercises-6.5-in-the-notes",
    "href": "chapter6.html#exercises-6.5-in-the-notes",
    "title": "6  Iteration-based Function Optimization",
    "section": "6.1 Exercises (6.5 in the notes)",
    "text": "6.1 Exercises (6.5 in the notes)\n1. Suppose for every individual in a small pre-clinical study, it has been recorded how many epileptic seizures are observed (outcome \\(y\\)) and whether the individual is receiving a standard treatment (covariate \\(x=0\\)) or experimental medication (covariate \\(x=1\\)). The data are:\n\n\n\nSubject \\(i\\)\nTreatment \\(x\\)\n# Seizures \\(y\\)\n\n\n\n\n1\n1\n12\n\n\n2\n1\n15\n\n\n3\n1\n17\n\n\n4\n0\n8\n\n\n5\n0\n11\n\n\n6\n0\n5\n\n\n\nA Poisson regression model is put forward for these data, with linear predictor \\(\\theta_i = \\beta_0 + \\beta_1 x_i\\). Starting from \\(\\boldsymbol{\\beta}^{(0)} = (0,0)'\\), do the following: Derive the likelihood equations. Can they be solved analytically in this case? Perform the first five steps of the Newton-Raphson algorithm to find the maximum of the likelihood. Put your results in a table with as columns: Iteration number, current point, and log-likelihood value. Do the same for Fisher-scoring.\nSolution\nThe Poisson model yields\n\\[\nY \\sim \\text{Poisson}(\\lambda),\n~ \\text{with} ~\nf(y|\\theta, \\phi) = \\frac{e^{-\\lambda}\\lambda^y}{y!},\n\\]\nand thus the likelihood \\(L\\) and log-likelihood \\(\\ell\\) are defined as\n\\[\n\\begin{aligned}\nL &= \\prod^6_{i=1} \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-e^{(\\beta_0 + \\beta_1 x_i)}} e^{(\\beta_0 \\beta_1 x_i)y_i}}{y_i!} \\\\\n\\ell &= \\sum^6_{i=1} y_i \\log \\lambda - \\lambda - \\log (y_i!) \\\\\n&= \\sum^6_{i=1} y_i(\\beta_0 + \\beta_1 x_i) - e^{(\\beta_0 + \\beta_1 x_i)} - \\log (y_i!).\n\\end{aligned}\n\\]\nAccordingly, the first-order partial derivatives are defined as\n\\[\n\\begin{aligned}\n\\frac{\\partial \\ell}{\\partial \\beta_0} &=\n\\sum^6_{i=1} y_i - e^{(\\beta_0 - \\beta_1 x_i)}, \\\\\n\\frac{\\partial \\ell}{\\partial \\beta_1} &=\n\\sum^6_{i=1} x_i y_i - x_i e^{(\\beta_0 - \\beta_1 x_i)},\n\\end{aligned}\n\\]\nand hence the Gradient (i.e., Score equation) can be written as\n\\[\n\\nabla \\ell(\\beta_0, \\beta_1) = S(\\theta) = \\begin{pmatrix}\n\\sum^6_{i=1} y_i - e^{(\\beta_0 - \\beta_1 x_i)}, \\\\\n\\sum^6_{i=1} x_i (y_i - e^{(\\beta_0 - \\beta_1 x_i)}).\n\\end{pmatrix}\n\\]\nAdditionally, the second-order partial derivates are defined as\n\\[\n\\begin{aligned}\n\\frac{\\partial^2 \\ell}{\\partial \\beta_0^2} &=\n\\sum^6_{i=1} - e^{(\\beta_0 - \\beta_1 x_i)}, \\\\\n\\frac{\\partial^2 \\ell}{\\partial \\beta_1^2} &=\n\\sum^6_{i=1} - x_i^2 e^{(\\beta_0 - \\beta_1 x_i)}, \\\\\n\\frac{\\partial^2 \\ell}{\\partial \\beta_0 \\partial \\beta_1} &=\n\\sum^6_{i=1} - x_i e^{(\\beta_0 - \\beta_1 x_i)}, \\\\\n\\end{aligned}\n\\]\nsuch that the Hessian \\(\\nabla^2 \\ell(\\beta_0, \\beta_1)\\) can be written as\n\\[\n\\nabla^2 \\ell(\\beta_0, \\beta_1) =\n\\begin{pmatrix}\n\\sum^6_{i=1} - e^{(\\beta_0 - \\beta_1 x_i)} & \\\\\n\\sum^6_{i=1} - x_i e^{(\\beta_0 - \\beta_1 x_i)} &\n\\sum^6_{i=1} - x_i^2 e^{(\\beta_0 - \\beta_1 x_i)}\n\\end{pmatrix}.\n\\]\nSetting the first-order partial derivatives to zero and filling in the data yields\n\\[\nS(\\theta) = \\begin{pmatrix}\n68 - 3e^{(\\beta_0 + \\beta_1)} - 3e^{(\\beta_0)} \\\\\n44 - 3e^{(\\beta_0 + \\beta_1)}\n\\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\n\\]\nHence, we have\n\\[\n\\begin{aligned}\n44 - 3e^{(\\beta_0 + \\beta_1)} &= 0 \\\\\n3e^{(\\beta_0 + \\beta_1)} &= 44,\n\\end{aligned}\n\\]\nand thus\n\\[\n\\begin{aligned}\n68 - 3e^{(\\beta_0)} &= 44 \\\\\n3e^{(\\beta_0)} &= 24 \\\\\ne^{(\\beta_0)} &= 8 \\\\\n\\beta_0 &= \\log 8 \\approx 2.0794.\n\\end{aligned}\n\\]\nFilling this into the previous equation yields\n\\[\n\\begin{aligned}\n3e^{(\\log 8 + \\beta_1)} &= 44 \\\\\n\\log 44 - \\log 3 - \\log 8 &= \\beta_1 \\approx 0.6061\n\\end{aligned}\n\\]"
  }
]